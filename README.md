# TA-Segmentation-Corpus
We exploited corpora that exist for TA in order to propose a SBD system. We first carry out a set of preprocessing steps in order to clean, correct spelling errors, tokenise the words and identify sentences boundaries. 
We present an extract of the collected dataset. 

In Corpus_ALL, we present the corpus that we used for the sentence segmentation of the three forms of Tunisian Dialect. The corpus is composed of 260.364 words and 33.581 sentences. It is manually normalized according to the orthographic convention CODA-TA. Also, sentence segmentation has been validated by native experts.

Reference: Asma Mekki, Inès Zribi, Mariem Ellouze et Lamia Hadrich Belguith, « Sentence boundary detection of various forms of Tunisian Arabic », Language Resources and Evaluation, pages 1-29, 2021. 

DOI: 10.1007/S10579-021-09538-4
